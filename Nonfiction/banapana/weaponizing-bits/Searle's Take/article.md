---
Title: Whither Apple Intelligence?
Date: 27-03-2025
Tags: AI, Apple, Help, Launchpad, Siri, support
---

# How AI Is Used In War Today – The Banapana Take

Because the war in Ukraine is the first real‑world sandbox where the “weaponized bits” you read about in 2005 are finally being tested, and because every time we talk about drones or 3‑D printers we’re really talking about the same old question: “Who gets to decide who lives and who dies?”

1. The Bit‑to‑Bullet Pipeline
When I first read Nicholas Negroponte’s 1995 Wired essay, “Bits and Atoms,” the punchline was simple: the value of a thing is no longer in its metal, but in the code that runs it. Fast forward to 2024, and that “code” is now a robotic arm that can shoot without a human hand. The 2005 “Weaponizing Bits” post you shared still feels eerily prescient—because the “bits” are no longer just data; they’re directives that can be executed in the field.

The transition from atoms to bits has been happening across commerce, but war is where the shift feels most delocalized (see the 2005 reference to drones and 3‑D printers). The war in Ukraine is a living lab where those delocalized bits are being turned into killing (or at least, targeting) software. And the irony? The very same companies that built your smartphone now fund a drone‑control platform called Brave1.

2. Ukraine’s AI Playbook
Tech	What It Does	Where It Stands Today
Autonomous drones	Tracks & engages targets without a human in the loop.	“True killer robots” are now a reality on Ukrainian skies (see The Verge article on the “Ukrainian drone swarm”).
Dog‑like robots (e.g. BAD One)	Thermal imaging, mine detection, ammo resupply.	The UK’s Alliance is already field‑testing them in real combat zones.

Autonomous machine guns	AI identifies enemies; human operator authorises fire.	Still human‑in‑the‑loop, but the line is blurring.

Facial recognition (Clearview)	Identifies Russian soldiers crossing borders.	Raises legal & ethical red flags—see The Guardian’s coverage of facial‑rec tech in Ukraine.
Humanitarian AI	Road & infrastructure mapping, landmine clearance, refugee resettlement.	These are the soft side of AI war—yet they’re just as data‑hungry.

Link‑heavy note:

3. Ethics: The Hot vs Cool Media of War
McLuhan’s hot/cool dichotomy still applies. A drone camera is hot—it gives us an amplified, hyper‑real view of the battlefield. Yet the human experience is cool—the soldier’s fight‑or‑flight response is dulled by distance. The result? War becomes easier to wage because the emotional cost to the attacker is reduced.

But this “cool” side isn’t harmless. The absence of a human face in the decision to kill can desensitize policy makers and the public. The 2022 U.S. general’s quote about a “fundamental change” is precisely that: the psychological distance between policy makers and battlefield casualties has widened to a point where accountability feels optional.

4. The “Tech‑Washing” Problem
The danger is twofold:

Over‑emphasis on AI – If we start painting the Ukrainian war as a battle of bots, we risk tech‑washing the raw brutality that still unfolds.
Under‑estimation of human cost – Even with autonomous systems, human soldiers are still in the mud, under artillery fire, and fighting for survival.
The 2024 New York Times piece on “AI‑enabled war crimes” reminds us that technology does not replace the need for human judgment; it complicates it.

5. Future‑Proofing: What’s Next?
AI + Autonomous Systems – We’re already seeing the first steps toward fully autonomous, decision‑making weapons. The key question: Will there ever be a moral line that stops this?
Civilian Spill‑over – If the tech is effective in war, it’s only a matter of time before civilian platforms (e.g., autonomous delivery drones) adopt similar targeting algorithms.
Regulation – International law is playing catch‑up. The Convention on Certain Conventional Weapons (CCW) has a “non‑combatant” track, but no concrete rules on autonomous weapons yet.
Link‑heavy note:

CCW Autonomous Weapon Discussion
https://ethics.mit.edu/2024/ai-military

AI Ethics in Military use
https://www.un.org/press/en/2024/ccw-autonomous-weapon.htm

6. Bottom Line
The war in Ukraine is the first real test of AI‑powered warfare. It’s a case study that shows:

Bits can now become bullets (literally).
Human judgment is still required, but the moral distance has widened.
Ethical questions are not just academic; they have immediate policy implications.
So, before you roll out your next AI‑driven app or drone prototype, ask yourself: Am I helping to reduce human casualties, or am I simply shifting the cost to a new generation of “remote” soldiers?

If you want more on how AI is shaping modern conflict, subscribe to our weekly digest—because the war isn’t going anywhere, and neither is the conversation.