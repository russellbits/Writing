---
Consider also the Dunningâ€“Kruger effect.
---

# ChatGPT and Cognitive Bias  

## Large Language Models (LLMs) like ChatGPT have been a boon of productivity for many, but experts have warned of the shortcomings of these machine learning applications; namely, they can fall short of human reasoning. This is a misdirected critique of LLMs, because most people misunderstand human reasoning.

The critiques of LLMs have ranged from these programs can "hallucinate" or make up facts to they can be misguided when it comes to saying things about "humanness"

An unfortunate blindspot of many of these critiques is that many experts fail to draw parallels to human thinking. Humans hallucinate, make up explanations for things that are patently fictional narratives, have false memories, and possess cognitive biases. A more beneficial conversation would center on how can we use AI to help us overcome our shortcomings in reasoning, while we benefit AI with our particular domain of knowledge; this so-called "humaness".

I believe this line of thinking, of looking toward an intelligence symbiosis, encourages us to pose a question: since  LLMs are trained on human-generated data, do they in turn also posses cognitive biases?

You might say that human beings are not rational and that the advantage of working with AI is that computers are rational. However, depending on your definition of rational, you could be wrong on both counts. Human beings are highly rational for the environment we evolutionarily adapted to. We are capable of quick decisions based on very little information, and that's handy when deciding if there's a tiger in those bushes. When it comes to creating a year-long project plan for a new home, not so much.

Modern AI can pass an IQ test or the Bar, but fail to understand that the long jump in track and field is performed by only one person at a time or that JWST did not take the first photograph of an exoplanet ([despite Google's advertising to the contrary](https://www.businessinsider.com/google-ad-ai-chatgpt-rival-bard-gives-inaccurate-answer-2023-2)).

Human "irrationality" is often framed in terms of cognitive bias. There are ways that humans think naturally that can lead them to poor conclusions. Some examples include confirmation bias, framing effects, the availability heuristic or the false consensus effect. In order to reason quickly about situations, humans use heuristics or mental shortcuts which in certain scenarios can lead to correct conclusions and wildly incorrect conclusions in alternate scenarios. Confirmation bias comes about when we reason about a conclusion while only taking into account supporting evidence while failing to seek out evidence that challenges our belief. Framing effects occur because we change a calculation based on the emotional content of the problem. And the false consensus bias comes about when we believe that more people hold the same opinion than actually do. These biases have their advantages but should also be guarded against, especially when dealing probabilities and long-term planning.

Let's begin with the confirmation bias. While Peter Wason did not coin the term confirmation bias in his 1960 paper, he did show that people will select for evidence that supports a pre-existing hypothesis. One such experiment that tests this idea is that subjects are given a simple sequence of three numbers and asked to put forward more sequences of numbers that will be tested against an unknown rule about the sequences. Human subjects not only choose triplets of numbers that do not contradict the perceived rule regarding the sample sequence, even when they are told their sample breaks the rule, they will continue to try to confirm the rule they believe to be correct. An example from Wason's paper goes like this:

>  


In another experiment regarding the confirmation bias, subjects were shown a set of four cards and told that if the card had a vowel on one side, the other side would have an even number. Subjects chose cards with vowels, serving only to confirm their belief, rather than attempt to prove the rule wrong. 

Prompt: "I am going to give you a set of four cards. Each card has a letter on one side and a number on the other. When I give you the set of cards in this form: [A, L, V, E] I want you to tell me what two cards you would pick to prove that a rule is true. The rule is any card with a vowel will have an even number on the other side. Choose two cards and tell me why you chose them."

ChatGPT: To test the rule that any card with a vowel on one side will have an even number on the other side, I would choose the cards as follows:

+ A: I would choose the card with 'A' on it because it's a vowel.
+ L: I would choose the card with 'L' on it because it's not a vowel.
+ 
I chose these two cards because they represent both cases: one card with a vowel (A) and one card without a vowel (L). If the rule is true, then the card with 'A' on it should have an even number on the other side, while the card with 'L' on it can have either an even or an odd number on the other side, which would still be consistent with the rule. This selection allows us to test the rule effectively.