---
title: "Magazine Hyperbole Will Be Vastly Superior in the Future!"
created: 2007-07-16
tags: 
  - change-computing
  - computer-software
  - computing
  - dumb-brute-force-solutions
  - electronics
  - gui
  - high-school
  - human-technology
  - isp
  - one-technology
  - peer-to-peer
  - projector-jumble-software
  - quantum-computing
  - screen-real-estate
  - will-be
authors: 
  - admin
---

Wow. I found an article over at \[pcmag.com\](http://www.pcmag.com) titled "Five Ideas That Will Reinvent Modern Computing." I thought, \*maybe two out of five wouldn't be bad\*. But not one? Not \*one\* of the ideas they cite will change modern computing. It really made me wonder, \*do the editors at PCmag.com use computers\*? I'm serious, not one of the items that they mention will have an impact on modern computing. And let me stress that: \*modern\* computing---meaning computing in the next five to ten years. The one technology that might have an impact that they cite (which, really, is a gimme) is quantum computing. No doubt, quantum computing (which is theoretical and still might not happen on a manufacturing scale) \*could\* change computing. But it won't change anything for twenty years. That's not \*modern\* computing. But the other technologies they cite are irrelevant or just banal.

1\. \[Build giant displays with multiple projectors\](http://www.pcmag.com/article2/0,1895,2147448,00.asp). Translation: Bigger screens will change modern computing! Really? Really. That's funny because \[a friend of mine\](http://spacematic.net/?p=222) actually uses a 40" flat panel LCD for his home computer and as far as I can tell, he computes the same as me. Granted, this projector-jumble software will be great in 5 years when High School kids can pick up junked projectors and use them together at a party. But the projectors \*will be\* junk because of massive \[OLEDs\](http://electronics.howstuffworks.com/oled3.htm), \[digital paper\](http://www.eink.com) or \[laser displays\](http://www.itwire.com.au/content/view/6216/532/) (set to come out next year). Regardless of the state of the projector market though, I fail to see how larger screens "change modern computing."

2\. \[The mid-air mouse\](http://www.pcmag.com/article2/0,1895,2147449,00.asp). The mouse is dead! It really doesn't matter if you can hold it. 3rd generation interfaces are making \[tactile digital information\](http://www.youtube.com/watch?v=89sz8ExZndc) that you \[directly interact with\](http://www.youtube.com/watch?v=0h-RhyopUmc) a reality, and 4th generation interfaces will \[bring that tactile aspect into 3 dimensions\](http://www.youtube.com/watch?v=Lfp8id6bpDU). ((For those keeping count, the first generation computer interface was the command-line or language use interface or LUI. The second generation interface was the graphic user interface, or the GUI. I don't know if that means that we will call tactile user interfaces TUIs, but I think we should because it's the only thing that sounds even more silly than GUI.)) Interfaces that require the removal of elements of the direct manipulation of reality we already possess are no longer necessary. The mouse works on a two dimensional plane, \*and\* is located in a physically different place than the symbols that represent your data. Technology is evolving toward the way that humans interact with reality. That is largely due to the fact that technology's form factors can change relatively faster than our own. And that extra degree of freedom in the third dimension and that direct (as opposed to space-shifted) access to symbols will be the future. We'll be interacting directly with our data, either on a screen with multi-touch or gestures or in augmented reality with direct manipulation. You don't need a mouse for reality, why would you need one for augmented reality? For that, you have hands. This "midair mouse" will go the way of tablet input---a curiosity. It will not change modern computing.

3\. \[Quantum computing\](http://www.pcmag.com/article2/0,1895,2147450,00.asp). Highly theoretical. 20 years away. I can see how this changes the future of computing, but how does this have any affect on \*modern\* computing. Incidentally, they never explain why they call Quantum Computing the "perfect machine". Quantum computer software will still have bugs. Quantum bugs. It's funny if you say it out loud. And they will not change modern computing.

4\. \[Extreme peer-to-peer\](http://www.pcmag.com/article2/0,1895,2147451,00.asp). Dumbest. Idea. Ever. Do we seriously want the network to be aware of what content we're requesting!? Not only is this a complete invitation to re-invent DRM and make it work on lower levels of the network, it's just a dumb way to handle privacy. Encrypt the network, then we'll talk. Besides, when it comes to the battle of technologies, dumb brute force solutions tend to be implemented more often. Who cares if you're shipping out the same 6,000 copies of a movie file when the pipes are fat enough to push \[terabits\](http://www.internetnews.com/bus-news/article.php/279841)? This development will not change modern computing because the first ISP network tech that tries to implement it is going to get stabbed with a fork. By me.

5\. \[Man-made brain\](http://www.pcmag.com/article2/0,1895,2147452,00.asp). Good. You can build an artificial mouse brain with a massive, massive supercomputer. Because mice, really, when you think about it, have done more than any other animal in human history to advance human technology.

I fail to understand how \*editors\* (as opposed to say, mail clerks) of a computer magazine could really not be able to see the obvious trends in modern computing right now. Sure, screen real estate will continue to increase (until screens mostly disappear) but that's really no different than predicting that CPUs will double in power ever 18 months. ((A prediction so reliable it's referred to as Moore's Law. Of course, it's \*not\* a law, it's an observation, but "law" is more fun to say.)) Data is going to become tactile. If you want to guess at what engineering developments are really \[going to matter\](http://www.apple.com/iphone/) to modern computing, that's really all you need to worry about.
